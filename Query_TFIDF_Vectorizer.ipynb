{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:19:59.036655Z",
     "start_time": "2019-05-15T10:19:38.757958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train data is: 145449\n",
      "Length of the dev data is: 5001\n",
      "Length of the dev result data is: 5001\n",
      "Length of the test data is: 14997\n",
      "Length of the corpus is: 25248397\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('train.json', 'r') as f:  # load training dataset\n",
    "        train_data = json.load(f)   \n",
    "print(\"Length of the train data is: \" + str(len(train_data)))\n",
    "\n",
    "with open('devset.json', 'r') as f1:  # load dev dataset\n",
    "        dev_data = json.load(f1) \n",
    "print(\"Length of the dev data is: \" + str(len(dev_data)))\n",
    "\n",
    "with open('devset_result.json', 'r') as f2:  # store result \n",
    "        res_data = json.load(f2) \n",
    "print(\"Length of the dev result data is: \" + str(len(res_data)))\n",
    "\n",
    "with open('test-unlabelled.json', 'r') as f3:  # store result \n",
    "     test_data = json.load(f3) \n",
    "print(\"Length of the test data is: \" + str(len(test_data)))\n",
    "        \n",
    "# appeand all the wiki txt sentences to one document\n",
    "def loadfile(folder): \n",
    "    corpus = []\n",
    "    list_of_files = os.listdir(folder)\n",
    "    \n",
    "    for file in list_of_files:\n",
    "        try:\n",
    "            filename = os.path.join(folder, file)\n",
    "            with open(filename, 'r') as doc:\n",
    "                for line in doc:\n",
    "                    corpus.append(line)     \n",
    "        except Exception as e:\n",
    "            print(\"No files found here!\")\n",
    "            raise e\n",
    "    return corpus\n",
    "corpus = loadfile(\"wiki-pages-text\")\n",
    "print(\"Length of the corpus is: \" + str(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:23:51.639510Z",
     "start_time": "2019-05-15T10:23:39.485098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_identifier</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>0</td>\n",
       "      <td>Alexander McNair -LRB- May 5   1775 -- March 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>1</td>\n",
       "      <td>He was the first Governor of Missouri from its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>4</td>\n",
       "      <td>McNair was born in Lancaster in the Province o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>5</td>\n",
       "      <td>His grandfather   David McNair   Sr.   immigra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>6</td>\n",
       "      <td>David McNair   Jr.   Alexander 's father -LRB-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>7</td>\n",
       "      <td>Alexander went to school as a child   and atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>8</td>\n",
       "      <td>He reached an agreement with his mother and br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>9</td>\n",
       "      <td>Alexander was defeated .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>10</td>\n",
       "      <td>He became a member of the Pennsylvania militia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alexander_McNair</td>\n",
       "      <td>13</td>\n",
       "      <td>In 1804   McNair traveled to what is now Misso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_identifier sentence_number  \\\n",
       "0  Alexander_McNair               0   \n",
       "1  Alexander_McNair               1   \n",
       "2  Alexander_McNair               4   \n",
       "3  Alexander_McNair               5   \n",
       "4  Alexander_McNair               6   \n",
       "5  Alexander_McNair               7   \n",
       "6  Alexander_McNair               8   \n",
       "7  Alexander_McNair               9   \n",
       "8  Alexander_McNair              10   \n",
       "9  Alexander_McNair              13   \n",
       "\n",
       "                                       sentence_text  \n",
       "0  Alexander McNair -LRB- May 5   1775 -- March 1...  \n",
       "1  He was the first Governor of Missouri from its...  \n",
       "2  McNair was born in Lancaster in the Province o...  \n",
       "3  His grandfather   David McNair   Sr.   immigra...  \n",
       "4  David McNair   Jr.   Alexander 's father -LRB-...  \n",
       "5  Alexander went to school as a child   and atte...  \n",
       "6  He reached an agreement with his mother and br...  \n",
       "7                         Alexander was defeated .\\n  \n",
       "8  He became a member of the Pennsylvania militia...  \n",
       "9  In 1804   McNair traveled to what is now Misso...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.DataFrame(corpus[:1000])\n",
    "corpus_df.columns = ['text']\n",
    "\n",
    "corpus_df['page_identifier'] = corpus_df.text.apply(lambda x: x.split(' ')[0])  \n",
    "corpus_df['sentence_number'] = corpus_df.text.apply(lambda x: x.split(' ')[1]) \n",
    "corpus_df['sentence_text'] = corpus_df.text.apply(lambda x: x.split(' ')[2:])  \n",
    "corpus_df['sentence_text'] = [','.join(map(str, l)) for l in corpus_df['sentence_text']]\n",
    "corpus_df[\"sentence_text\"] = corpus_df['sentence_text'].str.replace(',',' ')\n",
    "corpus_df = corpus_df.drop('text', 1)\n",
    "\n",
    "print(corpus_df.shape)\n",
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:25:45.746755Z",
     "start_time": "2019-05-15T10:25:44.080650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zhangyiming/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "nltk.download('wordnet')\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def pre_process(comment) -> str:\n",
    "    # lower cased\n",
    "    comment = comment.lower()\n",
    "    # tokenize\n",
    "    words = tokenizer.tokenize(comment)\n",
    "    # lemmatize \n",
    "    words = [lemmatize(w) for w in words]\n",
    "    processed_comment = \" \".join(words)\n",
    "    return processed_comment\n",
    "\n",
    "def process_dataset(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    processed_corpus = dataset['sentence_text'].apply(lambda text: pre_process(text))\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the corpus dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:27:14.785422Z",
     "start_time": "2019-05-15T10:27:14.628774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.150596\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexander mcnair lrb may 5 1775 march 18 1826 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he be the first governor of missouri from it e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mcnair be bear in lancaster in the province of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>his grandfather david mcnair sr immigrate to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>david mcnair jr alexander s father lrb b 1736 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alexander go to school a a child and attend on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>he reach an agreement with his mother and brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alexander be defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>he become a member of the pennsylvania militia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in 1804 mcnair travel to what be now missouri ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_text\n",
       "0  alexander mcnair lrb may 5 1775 march 18 1826 ...\n",
       "1  he be the first governor of missouri from it e...\n",
       "2  mcnair be bear in lancaster in the province of...\n",
       "3  his grandfather david mcnair sr immigrate to p...\n",
       "4  david mcnair jr alexander s father lrb b 1736 ...\n",
       "5  alexander go to school a a child and attend on...\n",
       "6  he reach an agreement with his mother and brot...\n",
       "7                                alexander be defeat\n",
       "8  he become a member of the pennsylvania militia...\n",
       "9  in 1804 mcnair travel to what be now missouri ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "processed_corpus_df = pd.DataFrame(process_dataset(corpus_df))\n",
    "processed_corpus_df.to_pickle(\"./processed_corpus.pkl\")\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)\n",
    "processed_corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:27:55.759220Z",
     "start_time": "2019-05-15T10:27:55.749420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexander mcnair lrb may 5 1775 march 18 1826 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he be the first governor of missouri from it e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mcnair be bear in lancaster in the province of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>his grandfather david mcnair sr immigrate to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>david mcnair jr alexander s father lrb b 1736 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alexander go to school a a child and attend on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>he reach an agreement with his mother and brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alexander be defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>he become a member of the pennsylvania militia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in 1804 mcnair travel to what be now missouri ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_text\n",
       "0  alexander mcnair lrb may 5 1775 march 18 1826 ...\n",
       "1  he be the first governor of missouri from it e...\n",
       "2  mcnair be bear in lancaster in the province of...\n",
       "3  his grandfather david mcnair sr immigrate to p...\n",
       "4  david mcnair jr alexander s father lrb b 1736 ...\n",
       "5  alexander go to school a a child and attend on...\n",
       "6  he reach an agreement with his mother and brot...\n",
       "7                                alexander be defeat\n",
       "8  he become a member of the pennsylvania militia...\n",
       "9  in 1804 mcnair travel to what be now missouri ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_processed_corpus_df = pd.read_pickle(\"./processed_corpus.pkl\")\n",
    "print(load_processed_corpus_df.shape)\n",
    "load_processed_corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Sklearn to build TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:31:49.758291Z",
     "start_time": "2019-05-15T10:31:49.706963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.046993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "start1 = datetime.datetime.now()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit(load_processed_corpus_df['sentence_text'])\n",
    "\n",
    "pickle.dump(tfidf, open(\"tfidf.pickle\",\"wb\"))\n",
    "\n",
    "end1 = datetime.datetime.now()\n",
    "print(end1-start1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a dictionary for page identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T10:37:27.045525Z",
     "start_time": "2019-05-15T10:37:27.038834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of keys = 221\n",
      "['Alexander McNair', 'Alatskivi', 'An American Girl Story - Maryellen 1955-COLON- Extraordinary Christmas', 'Alta Outcome Document', 'Al ‘Urban', 'Albano buoy system', 'Amuka', 'Aleksandr Abdulkhalikov', 'Amalia Ciardi Duprè', 'Akbil']\n"
     ]
    }
   ],
   "source": [
    "page_dictionary = {}\n",
    "\n",
    "for id, doc in enumerate(corpus[:1000]):\n",
    "    page_dictionary.setdefault((doc.split()[0].replace(\"_\", \" \")), []).append(id)\n",
    "\n",
    "# keys are the page identifier\n",
    "page_keys = list(page_dictionary.keys())\n",
    "print(\"Length of keys = {}\".format(len(page_keys)))\n",
    "print(page_keys[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a word dictionary for each word in page identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T12:25:10.876535Z",
     "start_time": "2019-05-15T12:25:10.857490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "McNair\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Alatskivi\n",
      "[18, 19, 20, 21]\n",
      "An\n",
      "[22, 23, 24, 25]\n",
      "American\n",
      "[22, 23, 24, 25]\n",
      "Girl\n",
      "[22, 23, 24, 25]\n",
      "Story\n",
      "[22, 23, 24, 25]\n",
      "-\n",
      "[22, 23, 24, 25]\n",
      "Maryellen\n",
      "[22, 23, 24, 25]\n",
      "1955-COLON-\n",
      "[22, 23, 24, 25]\n",
      "Extraordinary\n",
      "[22, 23, 24, 25]\n",
      "Christmas\n",
      "[22, 23, 24, 25]\n",
      "Alta\n",
      "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "Outcome\n",
      "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "Document\n",
      "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "Al\n",
      "[40, 41, 42]\n",
      "‘Urban\n",
      "[40, 41, 42]\n",
      "Albano\n",
      "[43, 44, 45]\n",
      "buoy\n",
      "[43, 44, 45]\n",
      "system\n",
      "[43, 44, 45]\n",
      "Amuka\n",
      "[46, 47, 48]\n",
      "Aleksandr\n",
      "[49, 50, 51, 52]\n",
      "Abdulkhalikov\n",
      "[49, 50, 51, 52]\n",
      "Amalia\n",
      "[53]\n",
      "Ciardi\n",
      "[53]\n",
      "Duprè\n",
      "[53]\n",
      "Akbil\n",
      "[54]\n",
      "All\n",
      "[55, 56, 57, 58]\n",
      "These\n",
      "[55, 56, 57, 58]\n",
      "Years\n",
      "[55, 56, 57, 58]\n",
      "Ambulance\n",
      "[59, 60, 61, 62, 63]\n",
      "services\n",
      "[59, 60, 61, 62, 63]\n",
      "of\n",
      "[59, 60, 61, 62, 63]\n",
      "Victoria\n",
      "[59, 60, 61, 62, 63]\n",
      "Alabama\n",
      "[64, 65]\n",
      "elections,\n",
      "[64, 65]\n",
      "2018\n",
      "[64, 65]\n",
      "Akarsu,\n",
      "[66, 67]\n",
      "Ardanuç\n",
      "[66, 67]\n",
      "Albertinovac\n",
      "[68, 69]\n",
      "All-India\n",
      "[70, 71, 72, 73, 74, 75]\n",
      "Yadav\n",
      "[70, 71, 72, 73, 74, 75]\n",
      "Mahasabha\n",
      "[70, 71, 72, 73, 74, 75]\n",
      "Alejandro\n",
      "[76]\n",
      "Rodríguez\n",
      "[76]\n",
      "López\n",
      "[76]\n",
      "Aleksandr\n",
      "[77, 78, 79]\n",
      "Luzin\n",
      "[77, 78, 79]\n",
      "American\n",
      "[80, 81, 82, 83]\n",
      "Thighs\n",
      "[80, 81, 82, 83]\n",
      "Alan\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
      "Brown\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
      "-LRB-Australian\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
      "politician-RRB-\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n"
     ]
    }
   ],
   "source": [
    "def create_keywords(keys, dic):\n",
    "    keywords = {}\n",
    "    for key in keys:\n",
    "        words = key.split()\n",
    "        for word in words:\n",
    "            print(word)\n",
    "            keywords[word] = dic[key]\n",
    "            print(dic[key])\n",
    "    return keywords\n",
    "\n",
    "# keywords should then remove stop words\n",
    "keywords = create_keywords(page_keys[:20], page_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T06:30:26.313238Z",
     "start_time": "2019-05-16T06:30:26.261984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 78, 79]\n"
     ]
    }
   ],
   "source": [
    "print(keywords['Aleksandr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find corpus index for all the claim tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:40:35.435277Z",
     "start_time": "2019-05-16T07:40:35.427810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron\n",
      "Burr\n",
      "killed\n",
      "Alexander\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Hamilton\n",
      "in\n",
      "Seaside\n",
      "Heights\n",
      "New\n",
      "Jersey\n",
      "CHiPs\n",
      "is\n",
      "an\n",
      "American\n",
      "[80, 81, 82, 83]\n",
      "romance\n",
      "film\n",
      "\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[80, 81, 82, 83]\n"
     ]
    }
   ],
   "source": [
    "retrieved_sentences = []  # results raw sentences contains the page identifiers that is in the claim\n",
    "\n",
    "test_claims = []\n",
    "test_claim1 = \"Aaron Burr killed Alexander Hamilton in Seaside Heights, New Jersey.\"\n",
    "test_claim2 = \"CHiPs is an American romance film.\"\n",
    "test_claims.append(test_claim1)\n",
    "test_claims.append(test_claim2)\n",
    "\n",
    "for test_claim in test_claims:\n",
    "    for token in tokenizer.tokenize(test_claim):\n",
    "        print(token)\n",
    "        if token in keywords:\n",
    "            print(keywords[token])\n",
    "            retrieved_sentences.append(keywords[token])\n",
    "        \n",
    "print(\"\\n\")      \n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "# retrieved sentence\n",
    "print(retrieved_sentences[0])\n",
    "print(retrieved_sentences[1])\n",
    "#print(flatten(retrieved_sentences))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all the corpus text for the claim tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:11:33.379370Z",
     "start_time": "2019-05-16T10:11:33.374425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "['Alexander McNair -LRB- May 5 , 1775 -- March 18 , 1826 -RRB- was an American frontiersman and politician .', 'He was the first Governor of Missouri from its entry as a state in 1820 , until 1824 .', 'McNair was born in Lancaster in the Province of Pennsylvania and grew up in Mifflin County .', 'His grandfather , David McNair , Sr. , immigrated to Pennsylvania from Donaghmore , County Donegal , Ireland around 1733 and had Scottish ancestors from Loch Lomond .', \"David McNair , Jr. , Alexander 's father -LRB- b. 1736 -RRB- , fought with General George Washington in the Trenton and Princeton campaigns in the winter of 1776 -- 77 , and died in February 1777 as a result of wounds received in battle and exposure when Alexander was less than two years old .\"]\n"
     ]
    }
   ],
   "source": [
    "# use retrieved sentence index to retrieve the raw sentence\n",
    "# only return the sentence text part\n",
    "\n",
    "retrieved_corpus = []\n",
    "for sentence in retrieved_sentences[0]:\n",
    "    #print(sentence)\n",
    "    #print(corpus[sentence])\n",
    "    retrieved_corpus.append(' '.join(corpus[sentence].split()[2:]))\n",
    "\n",
    "print(len(retrieved_corpus))\n",
    "print(retrieved_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:10:27.052849Z",
     "start_time": "2019-05-16T10:10:27.047925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander_McNair 0 Alexander McNair -LRB- May 5 , 1775 -- March 18 , 1826 -RRB- was an American frontiersman and politician .\n",
      "\n",
      "Alexander_McNair\n",
      "['Alexander', 'McNair', '-LRB-', 'May', '5', ',', '1775', '--', 'March', '18', ',', '1826', '-RRB-', 'was', 'an', 'American', 'frontiersman', 'and', 'politician', '.']\n",
      "Alexander McNair -LRB- May 5 , 1775 -- March 18 , 1826 -RRB- was an American frontiersman and politician .\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_corpus[0])\n",
    "\n",
    "print(retrieved_corpus[0].split()[0])\n",
    "\n",
    "print(retrieved_corpus[0].split()[2:])\n",
    "\n",
    "print(' '.join(retrieved_corpus[0].split()[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:12:23.861394Z",
     "start_time": "2019-05-16T10:12:23.814214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.043467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "start1 = datetime.datetime.now()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf = tfidf_vectorizer.fit(corpus[:1000])\n",
    "\n",
    "end1 = datetime.datetime.now()\n",
    "print(end1-start1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cosine between claim and retrieved text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:12:26.690835Z",
     "start_time": "2019-05-16T10:12:26.683039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron Burr killed Alexander Hamilton in Seaside Heights, New Jersey.\n",
      "\n",
      "\n",
      "['Alexander McNair -LRB- May 5 , 1775 -- March 18 , 1826 -RRB- was an American frontiersman and politician .', 'He was the first Governor of Missouri from its entry as a state in 1820 , until 1824 .', 'McNair was born in Lancaster in the Province of Pennsylvania and grew up in Mifflin County .', 'His grandfather , David McNair , Sr. , immigrated to Pennsylvania from Donaghmore , County Donegal , Ireland around 1733 and had Scottish ancestors from Loch Lomond .', \"David McNair , Jr. , Alexander 's father -LRB- b. 1736 -RRB- , fought with General George Washington in the Trenton and Princeton campaigns in the winter of 1776 -- 77 , and died in February 1777 as a result of wounds received in battle and exposure when Alexander was less than two years old .\", 'Alexander went to school as a child , and attended one term at the College of Philadelphia -LRB- now the University of Pennsylvania -RRB- .', \"He reached an agreement with his mother and brothers that the brothers would have a boxing match and that the winner would receive the father 's property .\", 'Alexander was defeated .', 'He became a member of the Pennsylvania militia and fought for the government in the Whiskey Rebellion in 1791 and 1794 .', 'In 1804 , McNair traveled to what is now Missouri , the United States having just acquired it following the Louisiana Purchase .', 'In that year he married Marguerite Suzanne de Reihle de Regal , the daughter of a French marquis .', 'He lived in St. Louis , Missouri , participated in Freemasonry as a member of St. Louis Lodge 111 , and served as a United States Marshal .', 'He also became a successful businessman , and served two terms on the Board of Trustees of the Town of St. Louis , in 1808 and 1813 .', 'On May 24 , 1813 , Stephen F. Austin , who was later responsible for the colonization of Texas , and for whom Austin , Texas is named , was commissioned an ensign in the Missouri militia .', 'Later in September , he enlisted as a private in the First Regiment of Mounted Militia commanded by Colonel Alexander McNair .', 'McNair was elected governor in 1820 , receiving 72 % of the vote and defeating the famous explorer William Clark .', 'After his time as governor , he worked in the Indian Department until his death .', 'He died of influenza , and is buried in Calvary Cemetery in St. Louis .']\n",
      "(1, 100)\n",
      "(18, 100)\n",
      "(1, 100)\n",
      "0.36191814962837165\n",
      "0.046463642102097635\n",
      "0.17030750888242607\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(test_claim1)\n",
    "print(\"\\n\")\n",
    "print(retrieved_corpus)\n",
    "\n",
    "test_claim1_list = []\n",
    "test_claim1_list.append(test_claim1)\n",
    "tfidf_claim1 = tfidf.transform(test_claim1_list)\n",
    "print(tfidf_claim1.shape)\n",
    "\n",
    "tfidf_retrieved = tfidf.transform(retrieved_corpus)\n",
    "print(tfidf_retrieved.shape)\n",
    "print(tfidf_retrieved[0].shape)\n",
    "\n",
    "print(1 - cosine(tfidf_claim1.toarray(),tfidf_retrieved[0].toarray()))\n",
    "print(1 - cosine(tfidf_claim1.toarray(),tfidf_retrieved[1].toarray()))\n",
    "print(1 - cosine(tfidf_claim1.toarray(),tfidf_retrieved[2].toarray()))\n",
    "#cosine_value = 1 - cosine(tfidf_claim1,tfidf_retrieved)\n",
    "#print(cosine_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T07:03:15.132938Z",
     "start_time": "2019-05-16T07:03:15.116479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colin Kaepernick became a starting quarterback during the 49ers 63rd season in the National Football League.\n",
      "['Colin', 'Kaepernick', 'became', 'a', 'starting', 'quarterback', 'during', 'the', '49ers', '63rd', 'season', 'in', 'the', 'National', 'Football', 'League']\n",
      "\n",
      "\n",
      "Tilda Swinton is a vegan.\n",
      "['Tilda', 'Swinton', 'is', 'a', 'vegan']\n",
      "\n",
      "\n",
      "Fox 2000 Pictures released the film Soul Food.\n",
      "['Fox', '2000', 'Pictures', 'released', 'the', 'film', 'Soul', 'Food']\n",
      "\n",
      "\n",
      "Anne Rice was born in New Jersey.\n",
      "['Anne', 'Rice', 'was', 'born', 'in', 'New', 'Jersey']\n",
      "\n",
      "\n",
      "Telemundo is a English-language television network.\n",
      "['Telemundo', 'is', 'a', 'English', 'language', 'television', 'network']\n",
      "\n",
      "\n",
      "Damon Albarn's debut album was released in 2011.\n",
      "['Damon', 'Albarn', 's', 'debut', 'album', 'was', 'released', 'in', '2011']\n",
      "\n",
      "\n",
      "There is a capital called Mogadishu.\n",
      "['There', 'is', 'a', 'capital', 'called', 'Mogadishu']\n",
      "\n",
      "\n",
      "Savages was exclusively a German film.\n",
      "['Savages', 'was', 'exclusively', 'a', 'German', 'film']\n",
      "\n",
      "\n",
      "Happiness in Slavery is a gospel song by Nine Inch Nails.\n",
      "['Happiness', 'in', 'Slavery', 'is', 'a', 'gospel', 'song', 'by', 'Nine', 'Inch', 'Nails']\n",
      "\n",
      "\n",
      "Andrew Kevin Walker is only Chinese.\n",
      "['Andrew', 'Kevin', 'Walker', 'is', 'only', 'Chinese']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " for key in list(res_data)[:10]:\n",
    "    res_data[key][\"evidence\"] = []\n",
    "    print(res_data[key][\"claim\"])\n",
    "    claim_query = res_data[key]['claim']\n",
    "    claim_tokens = tokenizer.tokenize(claim_query)\n",
    "    print(claim_tokens)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    for claim_token in claim_tokens:\n",
    "        if claim_token in keywords:\n",
    "            print(keywords[claim_token])\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
