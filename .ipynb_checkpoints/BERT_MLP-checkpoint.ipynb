{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy BERT server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction website: https://bert-as-service.readthedocs.io/en/latest/section/get-start.html  \n",
    "Download server and client:\n",
    "``` bash\n",
    "pip install -U bert-serving-server bert-serving-client  \n",
    "```\n",
    "Downlaod and unzip pretrained bert model(BERT-Large, Uncased, 1024 dimensional output):  \n",
    "``` bash\n",
    "cd ${model_path}\n",
    "wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip\n",
    "unzip uncased_L-24_H-1024_A-16.zip  \n",
    "```  \n",
    "\n",
    "Start bert server at local machine: \n",
    "``` bash\n",
    "bert-serving-start -model_dir ${model_path}/uncased_L-24_H-1024_A-16 -max_seq_len=100 -num_worker=1  \n",
    "bert-serving-start -model_dir /share/ShareFolder/uncased_L-24_H-1024_A-16/ -max_seq_len=150 -gpu_memory_fraction=0.9 -num_worker=1\n",
    "```\n",
    "Then, call from client end in python:\n",
    "``` python\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n",
    "bc.encode(['First do it', 'then do it right', 'then do it better'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T05:43:47.817994Z",
     "start_time": "2019-05-17T05:43:47.813975Z"
    }
   },
   "source": [
    "## Load data as Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T08:40:08.621365Z",
     "start_time": "2019-05-17T08:40:05.695425Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOINFO</th>\n",
       "      <th>REF</th>\n",
       "      <th>SUP</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_with_evi_text</th>\n",
       "      <th>evi_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>From the Earth to the Moon is a WGBH miniseries.</td>\n",
       "      <td>From the Earth to the Moon is a WGBH miniserie...</td>\n",
       "      <td>From the Earth to the Moon is a twelve-part HB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bhagat Singh was a movie role performed by Aja...</td>\n",
       "      <td>Bhagat Singh was a movie role performed by Aja...</td>\n",
       "      <td>Bhagat Singh -LRB- -LSB- pə̀ɡət̪ sɪ́ŋɡ -RSB- -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daz Dillinger is the owner of Bad Boy Records.</td>\n",
       "      <td>Daz Dillinger is the owner of Bad Boy Records....</td>\n",
       "      <td>It is one of two high schools in Campbellsvill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The release date of The Smurfs (film) changed ...</td>\n",
       "      <td>The release date of The Smurfs (film) changed ...</td>\n",
       "      <td>After having the release date changed three ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Morgan Freeman is incapable of being part of B...</td>\n",
       "      <td>Morgan Freeman is incapable of being part of B...</td>\n",
       "      <td>Freeman has appeared in many other box office ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael Jackson released the album Thriller.</td>\n",
       "      <td>Michael Jackson released the album Thriller. |...</td>\n",
       "      <td>His music videos , including those of `` Beat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Outlander (TV series) adapts novels.</td>\n",
       "      <td>Outlander (TV series) adapts novels. ||| Drago...</td>\n",
       "      <td>Dragonfly in Amber is the second book in the O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruce Springsteen was named MusiCares' person ...</td>\n",
       "      <td>Bruce Springsteen was named MusiCares' person ...</td>\n",
       "      <td>In 2009 , Springsteen was a Kennedy Center Hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Game of Thrones (season 3) had 0 episodes.</td>\n",
       "      <td>Game of Thrones (season 3) had 0 episodes. |||...</td>\n",
       "      <td>It was broadcast on Sunday at 9:00 pm in the U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anne Hathaway won the Critics' Choice Movie Aw...</td>\n",
       "      <td>Anne Hathaway won the Critics' Choice Movie Aw...</td>\n",
       "      <td>The Ballad .\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NOINFO  REF  SUP                                              claim  \\\n",
       "0       0    1    0   From the Earth to the Moon is a WGBH miniseries.   \n",
       "1       0    0    1  Bhagat Singh was a movie role performed by Aja...   \n",
       "2       1    0    0     Daz Dillinger is the owner of Bad Boy Records.   \n",
       "3       0    0    1  The release date of The Smurfs (film) changed ...   \n",
       "4       0    1    0  Morgan Freeman is incapable of being part of B...   \n",
       "5       0    0    1       Michael Jackson released the album Thriller.   \n",
       "6       0    0    1               Outlander (TV series) adapts novels.   \n",
       "7       0    0    1  Bruce Springsteen was named MusiCares' person ...   \n",
       "8       0    1    0         Game of Thrones (season 3) had 0 episodes.   \n",
       "9       1    0    0  Anne Hathaway won the Critics' Choice Movie Aw...   \n",
       "\n",
       "                                 claim_with_evi_text  \\\n",
       "0  From the Earth to the Moon is a WGBH miniserie...   \n",
       "1  Bhagat Singh was a movie role performed by Aja...   \n",
       "2  Daz Dillinger is the owner of Bad Boy Records....   \n",
       "3  The release date of The Smurfs (film) changed ...   \n",
       "4  Morgan Freeman is incapable of being part of B...   \n",
       "5  Michael Jackson released the album Thriller. |...   \n",
       "6  Outlander (TV series) adapts novels. ||| Drago...   \n",
       "7  Bruce Springsteen was named MusiCares' person ...   \n",
       "8  Game of Thrones (season 3) had 0 episodes. |||...   \n",
       "9  Anne Hathaway won the Critics' Choice Movie Aw...   \n",
       "\n",
       "                                            evi_text  \n",
       "0  From the Earth to the Moon is a twelve-part HB...  \n",
       "1  Bhagat Singh -LRB- -LSB- pə̀ɡət̪ sɪ́ŋɡ -RSB- -...  \n",
       "2  It is one of two high schools in Campbellsvill...  \n",
       "3  After having the release date changed three ti...  \n",
       "4  Freeman has appeared in many other box office ...  \n",
       "5  His music videos , including those of `` Beat ...  \n",
       "6  Dragonfly in Amber is the second book in the O...  \n",
       "7  In 2009 , Springsteen was a Kennedy Center Hon...  \n",
       "8  It was broadcast on Sunday at 9:00 pm in the U...  \n",
       "9                                     The Ballad .\\n  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_file_path = \"./JSONFiles/\" + \"train_with_text.json\"\n",
    "use_test_file = True\n",
    "if use_test_file:\n",
    "    test_file_path = './JSONFiles/' + 'test_with_text.json'\n",
    "else:\n",
    "    test_file_path = './JSONFiles/' + 'dev_with_text.json'\n",
    "\n",
    "with open(train_file_path, mode='r') as f:\n",
    "    train = json.load(f)\n",
    "with open(test_file_path, mode='r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "def load_training_data(dataset: dict) -> list:\n",
    "    dataset_list = []\n",
    "    for key in dataset.keys():\n",
    "        record = dataset.get(key)\n",
    "        claim = record.get(\"claim\")\n",
    "        evi_texts = record.get(\"evidence_texts\")\n",
    "        text = ''.join(evi_texts)\n",
    "        if len(text) == 0:\n",
    "            text = \"no word\"\n",
    "\n",
    "        SUP = NOINFO = REF = 0\n",
    "        if record.get(\"label\") == \"SUPPORTS\":\n",
    "            SUP = 1\n",
    "        elif record.get(\"label\") == \"REFUTES\":\n",
    "            REF = 1\n",
    "        else:\n",
    "            NOINFO = 1\n",
    "        dataset_record = {\n",
    "            \"claim\": claim,\n",
    "            \"evi_text\": text,\n",
    "            \"claim_with_evi_text\": claim + \" ||| \" + text,\n",
    "            \"SUP\": SUP,\n",
    "            \"NOINFO\": NOINFO,\n",
    "            \"REF\": REF\n",
    "        }\n",
    "        dataset_list.append(dataset_record)\n",
    "    return dataset_list\n",
    "\n",
    "def load_test_data(dataset: dict) -> list:\n",
    "    dataset_list = []\n",
    "    for key in dataset.keys():\n",
    "        record = dataset.get(key)\n",
    "        claim = record.get(\"claim\")\n",
    "        evi_index = record.get(\"evidence\")\n",
    "        evi_texts = record.get(\"evidence_texts\")\n",
    "        text = ''.join(evi_texts)\n",
    "        if len(text) == 0:\n",
    "            text = \"no word\"\n",
    "            \n",
    "        dataset_record = {\n",
    "            \"key\": key,\n",
    "            \"claim\": claim,\n",
    "            \"evidence\": evi_index,\n",
    "            \"claim_with_evi_text\": claim + \" ||| \" + text,\n",
    "            \"evi_text\": text\n",
    "        }\n",
    "        dataset_list.append(dataset_record)\n",
    "    return dataset_list\n",
    "\n",
    "train_df = pd.DataFrame(load_training_data(train))\n",
    "test_df = pd.DataFrame(load_test_data(test))\n",
    "\n",
    "train_df[0: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_with_evi_text</th>\n",
       "      <th>evi_text</th>\n",
       "      <th>evidence</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry III of France was murdered by the presid...</td>\n",
       "      <td>Henry III of France was murdered by the presid...</td>\n",
       "      <td>Henry III , Prince of Anhalt-Aschersleben -LRB...</td>\n",
       "      <td>[[Henry_III, 19], [Henry_III, 15], [Henry_III,...</td>\n",
       "      <td>183452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mary-Kate Olsen and Ashley Olsen are also know...</td>\n",
       "      <td>Mary-Kate Olsen and Ashley Olsen are also know...</td>\n",
       "      <td>She is an older sister of actress Elizabeth Ol...</td>\n",
       "      <td>[[Mary-Kate_Olsen, 3], [Mary-Kate_Olsen, 0], [...</td>\n",
       "      <td>212309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deepika Padukone played the lead role in a Hin...</td>\n",
       "      <td>Deepika Padukone played the lead role in a Hin...</td>\n",
       "      <td>Deepika Padukone -LRB- -LSB- d̪iːpɪkaː pəɖʊkoː...</td>\n",
       "      <td>[[Deepika_Padukone, 0], [Deepika_Padukone, 14]...</td>\n",
       "      <td>19160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRG Recording Studios is located in a hospital.</td>\n",
       "      <td>NRG Recording Studios is located in a hospital...</td>\n",
       "      <td>NRG Recording Studios is a recording facility ...</td>\n",
       "      <td>[[NRG_Recording_Studios, 0]]</td>\n",
       "      <td>36451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ayananka Bose is a director of cinematography.</td>\n",
       "      <td>Ayananka Bose is a director of cinematography....</td>\n",
       "      <td>He won the best cinematographer of Zee Cine Aw...</td>\n",
       "      <td>[[Ayananka_Bose, 2], [Ayananka_Bose, 0], [Ayan...</td>\n",
       "      <td>124694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aubrey Anderson-Emmons is a child actress.</td>\n",
       "      <td>Aubrey Anderson-Emmons is a child actress. |||...</td>\n",
       "      <td>Aubrey Frances Anderson-Emmons -LRB- born June...</td>\n",
       "      <td>[[Aubrey_Anderson-Emmons, 0], [Aubrey_Anderson...</td>\n",
       "      <td>23211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The University of Leicester discovered and ide...</td>\n",
       "      <td>The University of Leicester discovered and ide...</td>\n",
       "      <td>Later editions of the catalogue contained mino...</td>\n",
       "      <td>[[List_of_compositions_by_Franz_Schubert, 10]]</td>\n",
       "      <td>197637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gal Gadot was ranked ahead of Esti Ginzburgh f...</td>\n",
       "      <td>Gal Gadot was ranked ahead of Esti Ginzburgh f...</td>\n",
       "      <td>Gadot is primarily known for her role as Wonde...</td>\n",
       "      <td>[[Gal_Gadot, 1], [Gal_Gadot, 4], [Gal_Gadot, 5...</td>\n",
       "      <td>160309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pocahontas had a reception.</td>\n",
       "      <td>Pocahontas had a reception. ||| In a well-know...</td>\n",
       "      <td>In a well-known historical anecdote , she is s...</td>\n",
       "      <td>[[Pocahontas, 2], [Pocahontas, 8], [Pocahontas...</td>\n",
       "      <td>152201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Watertown, Massachusetts is in the United King...</td>\n",
       "      <td>Watertown, Massachusetts is in the United King...</td>\n",
       "      <td>Watertown is made up of six neighborhoods : Be...</td>\n",
       "      <td>[[Watertown,_Massachusetts, 6], [Watertown,_Ma...</td>\n",
       "      <td>157022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Henry III of France was murdered by the presid...   \n",
       "1  Mary-Kate Olsen and Ashley Olsen are also know...   \n",
       "2  Deepika Padukone played the lead role in a Hin...   \n",
       "3    NRG Recording Studios is located in a hospital.   \n",
       "4     Ayananka Bose is a director of cinematography.   \n",
       "5         Aubrey Anderson-Emmons is a child actress.   \n",
       "6  The University of Leicester discovered and ide...   \n",
       "7  Gal Gadot was ranked ahead of Esti Ginzburgh f...   \n",
       "8                        Pocahontas had a reception.   \n",
       "9  Watertown, Massachusetts is in the United King...   \n",
       "\n",
       "                                 claim_with_evi_text  \\\n",
       "0  Henry III of France was murdered by the presid...   \n",
       "1  Mary-Kate Olsen and Ashley Olsen are also know...   \n",
       "2  Deepika Padukone played the lead role in a Hin...   \n",
       "3  NRG Recording Studios is located in a hospital...   \n",
       "4  Ayananka Bose is a director of cinematography....   \n",
       "5  Aubrey Anderson-Emmons is a child actress. |||...   \n",
       "6  The University of Leicester discovered and ide...   \n",
       "7  Gal Gadot was ranked ahead of Esti Ginzburgh f...   \n",
       "8  Pocahontas had a reception. ||| In a well-know...   \n",
       "9  Watertown, Massachusetts is in the United King...   \n",
       "\n",
       "                                            evi_text  \\\n",
       "0  Henry III , Prince of Anhalt-Aschersleben -LRB...   \n",
       "1  She is an older sister of actress Elizabeth Ol...   \n",
       "2  Deepika Padukone -LRB- -LSB- d̪iːpɪkaː pəɖʊkoː...   \n",
       "3  NRG Recording Studios is a recording facility ...   \n",
       "4  He won the best cinematographer of Zee Cine Aw...   \n",
       "5  Aubrey Frances Anderson-Emmons -LRB- born June...   \n",
       "6  Later editions of the catalogue contained mino...   \n",
       "7  Gadot is primarily known for her role as Wonde...   \n",
       "8  In a well-known historical anecdote , she is s...   \n",
       "9  Watertown is made up of six neighborhoods : Be...   \n",
       "\n",
       "                                            evidence     key  \n",
       "0  [[Henry_III, 19], [Henry_III, 15], [Henry_III,...  183452  \n",
       "1  [[Mary-Kate_Olsen, 3], [Mary-Kate_Olsen, 0], [...  212309  \n",
       "2  [[Deepika_Padukone, 0], [Deepika_Padukone, 14]...   19160  \n",
       "3                       [[NRG_Recording_Studios, 0]]   36451  \n",
       "4  [[Ayananka_Bose, 2], [Ayananka_Bose, 0], [Ayan...  124694  \n",
       "5  [[Aubrey_Anderson-Emmons, 0], [Aubrey_Anderson...   23211  \n",
       "6     [[List_of_compositions_by_Franz_Schubert, 10]]  197637  \n",
       "7  [[Gal_Gadot, 1], [Gal_Gadot, 4], [Gal_Gadot, 5...  160309  \n",
       "8  [[Pocahontas, 2], [Pocahontas, 8], [Pocahontas...  152201  \n",
       "9  [[Watertown,_Massachusetts, 6], [Watertown,_Ma...  157022  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[0: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T10:22:02.299532Z",
     "start_time": "2019-05-17T10:22:02.296894Z"
    }
   },
   "source": [
    "### Construct and save bert features to file for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T10:22:01.605677Z",
     "start_time": "2019-05-17T08:53:06.342210Z"
    }
   },
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train, test claim encode\n",
    "# restart server with \n",
    "# bert-serving-start -model_dir /share/ShareFolder/uncased_L-24_H-1024_A-16/ -max_seq_len=150 -gpu_memory_fraction=0.9 -num_worker=1\n",
    "\n",
    "\n",
    "# train_claim_encode = bc.encode(list(train_df['claim']))\n",
    "# np.save(\"./BERT_MLP_encodings/train_claim_encode\", train_claim_encode)\n",
    "\n",
    "test_claim_encode = bc.encode(list(test_df['claim']))\n",
    "np.save(\"./BERT_MLP_encodings/test_claim_encode\", test_claim_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=150\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    }
   ],
   "source": [
    "# train, test evidence encode\n",
    "# restart server with \n",
    "# bert-serving-start -model_dir /share/ShareFolder/uncased_L-24_H-1024_A-16/ -max_seq_len=150 -gpu_memory_fraction=0.9 -num_worker=1\n",
    "\n",
    "# train_evi_encode = bc.encode(list(train_df['evi_text']))\n",
    "# np.save(\"./BERT_MLP_encodings/train_evi_encode\", train_evi_encode)\n",
    "\n",
    "test_evi_encode = bc.encode(list(test_df['evi_text']))\n",
    "np.save(\"./BERT_MLP_encodings/test_evi_encode\", test_evi_encode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train, test claim+evidence pair encode\n",
    "\n",
    "# train_pair_encode = bc.encode(list(train_df['claim_with_evi_text']))\n",
    "# np.save(\"./BERT_MLP_encodings/train_pair_encode\", train_pair_encode)\n",
    "\n",
    "test_pair_encode = bc.encode(list(test_df['claim_with_evi_text']))\n",
    "np.save(\"./BERT_MLP_encodings/test_pair_encode\", test_pair_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load bert features from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_claim_features = np.load(\"./BERT_MLP_encodings/train_claim_encode.npy\")\n",
    "test_claim_features = np.load(\"./BERT_MLP_encodings/test_claim_encode.npy\")\n",
    "\n",
    "train_evi_features = np.load(\"./BERT_MLP_encodings/train_evi_encode.npy\")\n",
    "test_evi_features = np.load(\"./BERT_MLP_encodings/test_evi_encode.npy\")\n",
    "\n",
    "train_pair_features = np.load(\"./BERT_MLP_encodings/train_pair_encode.npy\")\n",
    "test_pair_features = np.load(\"././BERT_MLP_encodings/test_pair_encode.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([train_claim_features, train_evi_features, train_pair_features], axis=1)\n",
    "y_train = train_df[train_df.columns[0:3]].values\n",
    "x_test = np.concatenate([test_claim_features, test_evi_features, test_pair_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145449, 3072)\n",
      "(145449, 3)\n",
      "(14997, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MLP model prototype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               614600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 624,803\n",
      "Trainable params: 624,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dense(units=50, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "# optimizer = Adam(lr=0.01)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "# callbacks\n",
    "filepath=\"best_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=3, verbose=0, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint, earlyStopping]\n",
    "\n",
    "# model.fit(x=x_train, y=y_train, batch_size=32, epochs=50, validation_split=0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters mannually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14997/14997 [==============================] - 0s 20us/step\n"
     ]
    }
   ],
   "source": [
    "# load from file\n",
    "model.load_weights(\"best_weights.hdf5\")\n",
    "y_test = model.predict(x_test, batch_size=128, verbose=1)\n",
    "y_test\n",
    "\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    if np.argmax(y_test[i]) == 0:\n",
    "        label = \"NOT ENOUGH INFO\"\n",
    "    elif np.argmax(y_test[i]) == 1:\n",
    "        label = \"REFUTES\"\n",
    "    else:\n",
    "        label = \"SUPPORTS\"\n",
    "    key = test_df['key'][i]\n",
    "    result_dict.update({\n",
    "        key:{\n",
    "            \"claim\": test_df['claim'][i],\n",
    "            \"label\": label,\n",
    "            \"evidence\": test_df['evidence'][i]\n",
    "        }\n",
    "    })\n",
    "    \n",
    "with open('result_on_dev.json', 'w') as outfile:\n",
    "    json.dump(result_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
