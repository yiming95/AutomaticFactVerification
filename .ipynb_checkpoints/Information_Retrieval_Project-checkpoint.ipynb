{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Retrieval\n",
    "\n",
    "This is the document retrieval and sentence retrieval part of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Unpack the zip file.\n",
    "    \n",
    "Unpack the 'wiki-pages-text.zip' in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def unpack():\n",
    "    with zipfile.ZipFile('wiki-pages-text.zip') as file:\n",
    "        file.extractall()\n",
    "unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load file. \n",
    "\n",
    "Load the training dataset and the wiki txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T08:25:09.269857Z",
     "start_time": "2019-05-06T08:24:22.039602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train data is: 145449\n",
      "Length of the document is: 25248397\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "with open('train.json', 'r') as f:  # load training dataset\n",
    "        train_data = json.load(f)   \n",
    "print(\"Length of the train data is: \" + str(len(train_data)))\n",
    "\n",
    "with open('devset.json', 'r') as f1:  # load dev dataset\n",
    "        dev_data = json.load(f1) \n",
    "\n",
    "with open('devset_result.json', 'r') as f2:  # store result \n",
    "        res_data = json.load(f2) \n",
    "        \n",
    "# appeand all the wiki txt sentences to one document\n",
    "def loadfile(folder): \n",
    "    document = []\n",
    "    list_of_files = os.listdir(folder)\n",
    "    \n",
    "    for file in list_of_files:\n",
    "        try:\n",
    "            filename = os.path.join(folder, file)\n",
    "            with open(filename, 'r') as doc:\n",
    "                for line in doc:\n",
    "                    document.append(line)     \n",
    "        except Exception as e:\n",
    "            print(\"No files found here!\")\n",
    "            raise e\n",
    "    return document\n",
    "document = loadfile(\"wiki-pages-text\")\n",
    "\n",
    "print(\"Length of the document is: \" + str(len(document)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preprocess \n",
    "Preprocess includes: strip punctuations, tokenize,lemma, lower case, remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:07.109919Z",
     "start_time": "2019-05-06T05:36:07.042428Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def preprocess(sentence):\n",
    "    norm_sentence = []\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence) # strip punctuations: remove ',' '.',etc.\n",
    "    tokens = nltk.tokenize.word_tokenize(sentence)  \n",
    "                \n",
    "    for token in tokens:\n",
    "        token = lemmatize(token)\n",
    "        token = token.lower() \n",
    "        if (token == \"no\" or token == \"not\"):  # keep no from stop words as it is useful for analysis\n",
    "            norm_sentence.append(token)  \n",
    "        if token not in stop_words:         # remove stop words\n",
    "            norm_sentence.append(token)                  \n",
    "    return norm_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build inverted index.\n",
    "Compute document term frequency, build <b> inverted index </b> and then uses BM25 to rank.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:35.608703Z",
     "start_time": "2019-05-06T05:36:35.579306Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def doc_term_freq(doc):\n",
    "    doc_term_freqs = []\n",
    "    for sentence in doc:\n",
    "        doc_term_freqs.append(Counter(sentence)) \n",
    "    return doc_term_freqs\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self, vocab, doc_term_freqs):\n",
    "        self.vocab = vocab\n",
    "        self.doc_len = [0] * len(doc_term_freqs)\n",
    "        self.doc_term_freqs = [[] for i in range(len(vocab))]\n",
    "        self.doc_ids = [[] for i in range(len(vocab))]\n",
    "        self.doc_freqs = [0] * len(vocab)\n",
    "        self.total_num_docs = 0\n",
    "        self.total_doc_len = 0\n",
    "        for docid, term_freqs in enumerate(doc_term_freqs):\n",
    "            doc_len = sum(term_freqs.values())\n",
    "            self.total_doc_len += doc_len\n",
    "            self.doc_len[docid] = doc_len\n",
    "            self.total_num_docs += 1\n",
    "            for term, freq in term_freqs.items():\n",
    "                term_id = vocab[term]\n",
    "                self.doc_ids[term_id].append(docid)\n",
    "                self.doc_term_freqs[term_id].append(freq)\n",
    "                self.doc_freqs[term_id] += 1\n",
    "\n",
    "    def num_terms(self):\n",
    "        return len(self.doc_ids)\n",
    "\n",
    "    def num_docs(self):\n",
    "        return self.total_num_docs\n",
    "\n",
    "    def docids(self, term):\n",
    "        term_id = self.vocab[term]\n",
    "        return self.doc_ids[term_id]\n",
    "\n",
    "    def freqs(self, term):\n",
    "        term_id = self.vocab[term]\n",
    "        return self.doc_term_freqs[term_id]\n",
    "\n",
    "    def f_t(self, term):\n",
    "        term_id = self.vocab[term]\n",
    "        return self.doc_freqs[term_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:34:26.554193Z",
     "start_time": "2019-05-06T05:34:26.541446Z"
    }
   },
   "source": [
    "#### 5. BM25 \n",
    "Okapi BM25 function is used to rank the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:59:54.233153Z",
     "start_time": "2019-05-06T05:59:54.213187Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "\n",
    "def BM25(query, index, k=5):\n",
    "    k1 = 1.2\n",
    "    k3 = 1.5\n",
    "    b = 0.75\n",
    "    # scores stores doc ids and their scores\n",
    "    scores = Counter()\n",
    "    length_average = index.total_doc_len/index.total_num_docs  # average length of document \n",
    "    \n",
    "    for term in query:\n",
    "        if term not in list(vocab.keys()):     # skip if the query word is not in the vocab\n",
    "            continue\n",
    "        N = index.num_docs()      # N: total number of documents\n",
    "        ft = index.f_t(term)       # ft: document frequency of term\n",
    "        docs = index.docids(term)    # docs: all doc ids that contain the term \n",
    "        dft = index.freqs(term)      # dft: all document freqs of the term \n",
    "        fqt = Counter(query)[term]   # fqt: frequency of tern t in query\n",
    "        \n",
    "        for num, docid in enumerate(docs):                                                                       \n",
    "            fdt = dft[num]                                #fdt: frequency of term t in document d   \n",
    "            length = sqrt(abs(index.doc_len[docid]))      # length: length of the doc\n",
    "            #BM25 consists of three parts\n",
    "            idf = log((N - ft + 0.5)/(ft + 0.5))\n",
    "            tf = ((k1 + 1) * fdt)/(k1 * ((1-b) + b * length/length_average) + fdt)\n",
    "            query_tf = (k3 + 1) * fqt / (k3 + fqt)\n",
    "            \n",
    "            scores[docid] +=  idf * tf * query_tf           \n",
    "    return scores.most_common(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-idf function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T07:50:06.412529Z",
     "start_time": "2019-05-06T07:50:06.403114Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf idf  function in homework 1\n",
    "# given a query and an index returns a list of the k highest scoring documents as tuples containing <docid,score>\n",
    "def tfidf(query, index, k=5):\n",
    "    \n",
    "    # scores stores doc ids and their scores\n",
    "    scores = Counter()\n",
    "    for term in query:   \n",
    "        \n",
    "        if term not in list(vocab.keys()):   # skip if the query word is not in the vocab\n",
    "            continue\n",
    "            \n",
    "        N = index.num_docs()      # N: total number of documents\n",
    "        ft = index.f_t(term)       # ft: document frequency of term\n",
    "        docs = index.docids(term)    # docs: all doc ids that contain the term \n",
    "        dft = index.freqs(term)      # dft: all document freqs of the term         \n",
    "        \n",
    "        for num, docid in enumerate(docs):                # num: index used for iterate the docs                                                        \n",
    "            fdt = dft[num]                                #fdt: frequency of term t in document d   \n",
    "            length = sqrt(abs(index.doc_len[docid]))      # length: length of the doc\n",
    "            tfidf = log(1 + fdt)*log(N/ft)                 # tfidf: construct the score formula \n",
    "            scores[docid] += tfidf/length                  # score: the final score\n",
    "\n",
    "    return scores.most_common(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use page identifier to reduce the search space.\n",
    "\n",
    "Build a dictionary that consists the <b>page identifier</b> as the key and the document index(ranges form 0 to 25248397 ） as value.\n",
    "\n",
    "Examples looks like: \"Alexander McNair\" : [1,2,3,4...18] \n",
    "\n",
    "<b>To do:</b> the keywords list may also consider synonyms for each keyword.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:50:31.187650Z",
     "start_time": "2019-05-06T05:49:17.304338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of keys = 5396106\n"
     ]
    }
   ],
   "source": [
    "final_dic = {}\n",
    "\n",
    "for id, doc in enumerate(document):\n",
    "    final_dic.setdefault((doc.split()[0].replace(\"_\", \" \")), []).append(id)\n",
    "\n",
    "keys = list(final_dic.keys())\n",
    "print(\"Length of keys = {}\".format(len(keys)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Retrieval Evidence\n",
    "<b>7.1</b> Given a query, tokenize it first, then for each token in the query, try to find it in the keys list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T06:59:01.908919Z",
     "start_time": "2019-05-06T06:59:01.898698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 216, 217, 260, 538, 670, 671, 684, 685, 686, 687, 776, 777, 896, 897, 898, 992, 993, 994, 995, 1065, 1066, 1067, 1068, 1069, 1123, 1143, 1144, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1393, 1394, 1395, 1484, 1588, 1589, 1590, 1591, 1592, 1593, 1654, 1655, 2221, 2222, 2223, 2224, 2225, 2268, 2269, 2270, 2271, 2272, 2273, 2279, 2280, 883, 884, 885, 886, 887, 888]\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "# Given a query, returns a list that contains all the document index values.\n",
    "def extract_sentences(query, keys, final_dic):\n",
    "    retrievaled_sentences = []\n",
    "    for word in  nltk.tokenize.word_tokenize(query):\n",
    "        for key in keys:\n",
    "            if re.search(word, key):\n",
    "                retrievaled_sentences.append(final_dic[key])\n",
    "            \n",
    "    retrievaled_sentences = [item for sublist in retrievaled_sentences for item in sublist]\n",
    "    return retrievaled_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7.2</b> If there is a match or substring match, then retrieve that sentence by using index value to find the raw sentence in txt file. \n",
    "\n",
    "<b>7.3</b> Find all the related sentences by this way and then builds a inverted index and \n",
    "uses BM25 to rank and to retrieval top K sentences as the evidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T08:18:21.065061Z",
     "start_time": "2019-05-06T08:18:21.042879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK  1 DOCID        7 SCORE 0.441 CONTENT Alexander_McNair 9 Alexander was defeated .\n",
      "\n",
      "RANK  2 DOCID        4 SCORE 0.240 CONTENT Alexander_McNair 6 David McNair , Jr. , Alexander 's father -LRB- b. 1736 -RRB- , fought with General George Washington in the Trenton and Princeton campaigns in the winter of 1776 -- 77 , and died in February 1777 as a result of wounds received in battle and exposure when Alexander was less than two years old .\n",
      "\n",
      "RANK  3 DOCID       14 SCORE 0.236 CONTENT Alexander_McNair 20 Later in September , he enlisted as a private in the First Regiment of Mounted Militia commanded by Colonel Alexander McNair .\n",
      "\n",
      "RANK  4 DOCID        0 SCORE 0.228 CONTENT Alexander_McNair 0 Alexander McNair -LRB- May 5 , 1775 -- March 18 , 1826 -RRB- was an American frontiersman and politician .\n",
      "\n",
      "RANK  5 DOCID        5 SCORE 0.228 CONTENT Alexander_McNair 7 Alexander went to school as a child , and attended one term at the College of Philadelphia -LRB- now the University of Pennsylvania -RRB- .\n",
      "\n",
      "[7, 4, 14, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "# Use the result from above step, find all the raw sentences in txt file.\n",
    "# return a list of the doc id orderd by rnaking tfidf or bm25 score.\n",
    "\n",
    "def retrieval_evidence(query, keys, final_dic):\n",
    "    processed_doc = [] # processed_docs stores the list of processed docs\n",
    "    vocab = {}\n",
    "    unique_id = 0\n",
    "    rank_result = []\n",
    "    \n",
    "    retrievaled_sentences = extract_sentences(query,keys,final_dic)\n",
    "    \n",
    "    # find the row sentences and save them in processed_doc\n",
    "    for retrievaled_sentence in retrievaled_sentences:\n",
    "        norm_sentence = preprocess(document[retrievaled_sentence])\n",
    "        for token in norm_sentence:\n",
    "            if token not in vocab:\n",
    "                vocab.update({token: unique_id})     \n",
    "                unique_id = unique_id + 1\n",
    "        processed_doc.append(norm_sentence) \n",
    "    \n",
    "    # calculate doc term freqs and build an inverted index\n",
    "    doc_term_freqs = doc_term_freq(processed_doc)\n",
    "    invindex = InvertedIndex(vocab, doc_term_freqs)\n",
    "    bm25_results = BM25(processed_query, invindex)\n",
    "    tfidf_results = tfidf(processed_query, invindex)\n",
    "    \n",
    "    for rank, res in enumerate(tfidf_results):\n",
    "        # print(\"RANK {:2d} DOCID {:8d} SCORE {:.3f} CONTENT {:}\".format(rank+1,res[0],res[1],document[res[0]]))\n",
    "        rank_result.append((res[0]))\n",
    "    return rank_result\n",
    "\n",
    "# test_query = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "test_query = \"Alexander Alatskivi\"\n",
    "print(retrieval_evidence(test_query,keys[:100],final_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 Write the result to json file.\n",
    "\n",
    "The dataset used is 'devset.json', the predicted result is 'devset_result.json'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T08:33:32.200470Z",
     "start_time": "2019-05-06T08:33:29.546450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK  1 DOCID        7 SCORE 1.328 CONTENT Alexander_McNair 9 Alexander was defeated .\n",
      "\n",
      "RANK  2 DOCID      431 SCORE 1.328 CONTENT Almenara,_Minas_Gerais 25 The municipality contains a small amount of the 50,890 ha Mata Escura Biological Reserve , created in 2003 .\n",
      "\n",
      "RANK  3 DOCID        4 SCORE 0.722 CONTENT Alexander_McNair 6 David McNair , Jr. , Alexander 's father -LRB- b. 1736 -RRB- , fought with General George Washington in the Trenton and Princeton campaigns in the winter of 1776 -- 77 , and died in February 1777 as a result of wounds received in battle and exposure when Alexander was less than two years old .\n",
      "\n",
      "RANK  4 DOCID      428 SCORE 0.722 CONTENT Almenara,_Minas_Gerais 20 In the rural area there were 983 farms in 2006 .\n",
      "\n",
      "RANK  5 DOCID       14 SCORE 0.710 CONTENT Alexander_McNair 20 Later in September , he enlisted as a private in the First Regiment of Mounted Militia commanded by Colonel Alexander McNair .\n",
      "\n",
      "RANK  1 DOCID       39 SCORE 1.327 CONTENT Alta_Outcome_Document 27 For example , the Indonesian Indigenous Peoples ' Alliance of the Archipelago wrote a letter to President Susilo Bambang Yudhoyono regarding Government of Indonesia objections to the UN over 2014 conference plans , which claimed Indonesian indigenous peoples had not been involved .\n",
      "\n",
      "RANK  2 DOCID      383 SCORE 1.327 CONTENT Alfred_Boquet 13 With Léopold Nègre he developed antigène méthylique -LRB- antigen-methyl -RRB- for treatment of tuberculosis .\n",
      "\n",
      "RANK  3 DOCID       36 SCORE 0.721 CONTENT Alta_Outcome_Document 21 indigenous peoples ' priorities for development with free , prior and informed consent ;\n",
      "\n",
      "RANK  4 DOCID      380 SCORE 0.721 CONTENT Alfred_Boquet 8 At the Pasteur Institute in Algiers he participated in development of the `` anticlaveleux-vaccine '' , a vaccine used for rapid vaccination of millions of sheep in North Africa and Europe .\n",
      "\n",
      "RANK  5 DOCID       46 SCORE 0.709 CONTENT Amuka 0 Amuka is the stage name used by singer/songwriter Sheila Brody .\n",
      "\n",
      "RANK  1 DOCID       25 SCORE 1.335 CONTENT An_American_Girl_Story_-_Maryellen_1955-COLON-_Extraordinary_Christmas 5 It is also the second American Girl film to feature the Maryellen character , the first being the short Maryellen and the Brightest Star starring Harlie Galloway .\n",
      "\n",
      "RANK  2 DOCID       22 SCORE 0.726 CONTENT An_American_Girl_Story_-_Maryellen_1955-COLON-_Extraordinary_Christmas 0 An American Girl Story - Maryellen 1955 : Extraordinary Christmas is a 2016 family-drama film starring Alyvia Alyn Lind in the title role , along with Mary McCormack and Madison Lawlor in supporting roles .\n",
      "\n",
      "RANK  3 DOCID       32 SCORE 0.714 CONTENT Alta_Outcome_Document 12 The ambition of the indigenous peoples involved was to have the document be accepted as an official United Nations document .\n",
      "\n",
      "RANK  4 DOCID       18 SCORE 0.689 CONTENT Alatskivi 0 Vallavanem Andu Tõrva\n",
      "\n",
      "RANK  5 DOCID       23 SCORE 0.689 CONTENT An_American_Girl_Story_-_Maryellen_1955-COLON-_Extraordinary_Christmas 1 The film takes place in mid-1950s Daytona Beach , Florida , centering on Maryellen Larkin 's life together with her big family , longing to stand out among her siblings and other relatives , and how she helped a number of young patients at a polio ward , Maryellen herself being a polio victim .\n",
      "\n",
      "RANK  1 DOCID       56 SCORE 1.323 CONTENT All_These_Years 1 It was later recorded by American country music group Sawyer Brown .\n",
      "\n",
      "RANK  2 DOCID       53 SCORE 0.719 CONTENT Amalia_Ciardi_Duprè 0 Amalia Ciardi Duprè -LRB- born 1934 -RRB- is an Italian sculptor and painter .\n",
      "\n",
      "RANK  3 DOCID       63 SCORE 0.707 CONTENT Ambulance_services_of_Victoria 10 In addition , a number of non-emergency patient transport companies operate under the Non-Emergency Patient Transport Act 2003 are use conventional ambulance equipped with emergency lights and sirens , and sometimes attend emergency cases .\n",
      "\n",
      "RANK  4 DOCID       49 SCORE 0.683 CONTENT Aleksandr_Abdulkhalikov 0 Aleksandr Rustamovich Abdulkhalikov -LRB- Александр Рустамович Абдулхаликов born 3 March 1975 -RRB- is a Russian professional football player .\n",
      "\n",
      "RANK  5 DOCID       54 SCORE 0.683 CONTENT Akbil 0 Akbil is a town and commune in Tizi Ouzou Province in northern Algeria .\n",
      "\n",
      "RANK  1 DOCID       39 SCORE 1.327 CONTENT Alta_Outcome_Document 27 For example , the Indonesian Indigenous Peoples ' Alliance of the Archipelago wrote a letter to President Susilo Bambang Yudhoyono regarding Government of Indonesia objections to the UN over 2014 conference plans , which claimed Indonesian indigenous peoples had not been involved .\n",
      "\n",
      "RANK  2 DOCID      383 SCORE 1.327 CONTENT Alfred_Boquet 13 With Léopold Nègre he developed antigène méthylique -LRB- antigen-methyl -RRB- for treatment of tuberculosis .\n",
      "\n",
      "RANK  3 DOCID       36 SCORE 0.721 CONTENT Alta_Outcome_Document 21 indigenous peoples ' priorities for development with free , prior and informed consent ;\n",
      "\n",
      "RANK  4 DOCID      380 SCORE 0.721 CONTENT Alfred_Boquet 8 At the Pasteur Institute in Algiers he participated in development of the `` anticlaveleux-vaccine '' , a vaccine used for rapid vaccination of millions of sheep in North Africa and Europe .\n",
      "\n",
      "RANK  5 DOCID       46 SCORE 0.709 CONTENT Amuka 0 Amuka is the stage name used by singer/songwriter Sheila Brody .\n",
      "\n",
      "RANK  1 DOCID       54 SCORE 1.322 CONTENT Akbil 0 Akbil is a town and commune in Tizi Ouzou Province in northern Algeria .\n",
      "\n",
      "RANK  2 DOCID       51 SCORE 0.718 CONTENT Aleksandr_Abdulkhalikov 2 He also holds Uzbekistani citizenship .\n",
      "\n",
      "RANK  3 DOCID       61 SCORE 0.706 CONTENT Ambulance_services_of_Victoria 4 The MAS was responsible for Melbourne and its outer suburbs while RAV was responsible for regional and rural areas of Victoria , except for the Alexandra , Marysville , and Eildon areas , which was serviced by ADAS .\n",
      "\n",
      "RANK  4 DOCID       47 SCORE 0.682 CONTENT Amuka 1 The name was coined by artist/producer Jahkey B , when they co-wrote the song `` Appreciate Me '' -LRB- the original title is : Jahkey B presents Amuka -RRB- .\n",
      "\n",
      "RANK  5 DOCID       52 SCORE 0.682 CONTENT Aleksandr_Abdulkhalikov 5 He is a twin brother of Aleksei Abdulkhalikov .\n",
      "\n",
      "RANK  1 DOCID       39 SCORE 1.327 CONTENT Alta_Outcome_Document 27 For example , the Indonesian Indigenous Peoples ' Alliance of the Archipelago wrote a letter to President Susilo Bambang Yudhoyono regarding Government of Indonesia objections to the UN over 2014 conference plans , which claimed Indonesian indigenous peoples had not been involved .\n",
      "\n",
      "RANK  2 DOCID      383 SCORE 1.327 CONTENT Alfred_Boquet 13 With Léopold Nègre he developed antigène méthylique -LRB- antigen-methyl -RRB- for treatment of tuberculosis .\n",
      "\n",
      "RANK  3 DOCID       36 SCORE 0.721 CONTENT Alta_Outcome_Document 21 indigenous peoples ' priorities for development with free , prior and informed consent ;\n",
      "\n",
      "RANK  4 DOCID      380 SCORE 0.721 CONTENT Alfred_Boquet 8 At the Pasteur Institute in Algiers he participated in development of the `` anticlaveleux-vaccine '' , a vaccine used for rapid vaccination of millions of sheep in North Africa and Europe .\n",
      "\n",
      "RANK  5 DOCID       46 SCORE 0.709 CONTENT Amuka 0 Amuka is the stage name used by singer/songwriter Sheila Brody .\n",
      "\n",
      "RANK  1 DOCID       10 SCORE 1.314 CONTENT Alexander_McNair 14 In that year he married Marguerite Suzanne de Reihle de Regal , the daughter of a French marquis .\n",
      "\n",
      "RANK  2 DOCID      354 SCORE 1.314 CONTENT Alternative_title 0 An alternative title is a media sales device most prominently used in film distribution .\n",
      "\n",
      "RANK  3 DOCID        7 SCORE 0.714 CONTENT Alexander_McNair 9 Alexander was defeated .\n",
      "\n",
      "RANK  4 DOCID      351 SCORE 0.714 CONTENT American_social_dancing_in_the_20th_century 6 For example , swing dancing is typically done to big band music , while jazz dance was done to jazz music .\n",
      "\n",
      "RANK  5 DOCID       17 SCORE 0.702 CONTENT Alexander_McNair 25 He died of influenza , and is buried in Calvary Cemetery in St. Louis .\n",
      "\n",
      "RANK  1 DOCID       83 SCORE 1.326 CONTENT American_Thighs 3 The songs and artwork are the same on both versions , but the DGC artwork is on glossy paper .\n",
      "\n",
      "RANK  2 DOCID      427 SCORE 1.326 CONTENT Almenara,_Minas_Gerais 19 There were 2 private hospitals with 180 beds -LRB- 2005 -RRB- .\n",
      "\n",
      "RANK  3 DOCID       80 SCORE 0.721 CONTENT American_Thighs 0 American Thighs is the first album by alternative rock band Veruca Salt .\n",
      "\n",
      "RANK  4 DOCID      424 SCORE 0.721 CONTENT Almenara,_Minas_Gerais 16 The main economic activity is cattle raising with over 89,000 head of cattle counted in 2006 .\n",
      "\n",
      "RANK  5 DOCID       90 SCORE 0.709 CONTENT Alan_Brown_-LRB-Australian_politician-RRB- 10 The Liberals had come up five seats short of winning the 1988 election , and it was thought that they would have won if not for a number of three-cornered contests in rural areas .\n",
      "\n",
      "RANK  1 DOCID       39 SCORE 1.346 CONTENT Alta_Outcome_Document 27 For example , the Indonesian Indigenous Peoples ' Alliance of the Archipelago wrote a letter to President Susilo Bambang Yudhoyono regarding Government of Indonesia objections to the UN over 2014 conference plans , which claimed Indonesian indigenous peoples had not been involved .\n",
      "\n",
      "RANK  2 DOCID       36 SCORE 0.732 CONTENT Alta_Outcome_Document 21 indigenous peoples ' priorities for development with free , prior and informed consent ;\n",
      "\n",
      "RANK  3 DOCID       46 SCORE 0.720 CONTENT Amuka 0 Amuka is the stage name used by singer/songwriter Sheila Brody .\n",
      "\n",
      "RANK  4 DOCID       32 SCORE 0.695 CONTENT Alta_Outcome_Document 12 The ambition of the indigenous peoples involved was to have the document be accepted as an official United Nations document .\n",
      "\n",
      "RANK  5 DOCID       37 SCORE 0.695 CONTENT Alta_Outcome_Document 23 relationship between governments , indigenous peoples and extractive industries regarding participation , access to decision-making and distribution of income .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Colin Kaepernick became a starting quarterback during the 49ers 63rd season in the National Football League.', 'label': 'NOT ENOUGH INFO', 'evidence': [['Alexander_McNair', '9'], ['Almenara,_Minas_Gerais', '25'], ['Alexander_McNair', '6'], ['Almenara,_Minas_Gerais', '20'], ['Alexander_McNair', '20']]}\n",
      "\n",
      "\n",
      "{'claim': 'Tilda Swinton is a vegan.', 'label': 'NOT ENOUGH INFO', 'evidence': [['Alta_Outcome_Document', '27'], ['Alfred_Boquet', '13'], ['Alta_Outcome_Document', '21'], ['Alfred_Boquet', '8'], ['Amuka', '0']]}\n",
      "\n",
      "\n",
      "{'claim': 'Fox 2000 Pictures released the film Soul Food.', 'label': 'SUPPORTS', 'evidence': [['An_American_Girl_Story_-_Maryellen_1955-COLON-_Extraordinary_Christmas', '5'], ['An_American_Girl_Story_-_Maryellen_1955-COLON-_Extraordinary_Christmas', '0'], ['Alta_Outcome_Document', '12'], ['Alatskivi', '0'], ['An_American_Girl_Story_-_Maryellen_1955-COLON-_Extraordinary_Christmas', '1']]}\n",
      "\n",
      "\n",
      "{'claim': 'Anne Rice was born in New Jersey.', 'label': 'NOT ENOUGH INFO', 'evidence': [['All_These_Years', '1'], ['Amalia_Ciardi_Duprè', '0'], ['Ambulance_services_of_Victoria', '10'], ['Aleksandr_Abdulkhalikov', '0'], ['Akbil', '0']]}\n",
      "\n",
      "\n",
      "{'claim': 'Telemundo is a English-language television network.', 'label': 'REFUTES', 'evidence': [['Alta_Outcome_Document', '27'], ['Alfred_Boquet', '13'], ['Alta_Outcome_Document', '21'], ['Alfred_Boquet', '8'], ['Amuka', '0']]}\n",
      "\n",
      "\n",
      "{'claim': \"Damon Albarn's debut album was released in 2011.\", 'label': 'REFUTES', 'evidence': [['Akbil', '0'], ['Aleksandr_Abdulkhalikov', '2'], ['Ambulance_services_of_Victoria', '4'], ['Amuka', '1'], ['Aleksandr_Abdulkhalikov', '5']]}\n",
      "\n",
      "\n",
      "{'claim': 'There is a capital called Mogadishu.', 'label': 'SUPPORTS', 'evidence': [['Alta_Outcome_Document', '27'], ['Alfred_Boquet', '13'], ['Alta_Outcome_Document', '21'], ['Alfred_Boquet', '8'], ['Amuka', '0']]}\n",
      "\n",
      "\n",
      "{'claim': 'Savages was exclusively a German film.', 'label': 'REFUTES', 'evidence': [['Alexander_McNair', '14'], ['Alternative_title', '0'], ['Alexander_McNair', '9'], ['American_social_dancing_in_the_20th_century', '6'], ['Alexander_McNair', '25']]}\n",
      "\n",
      "\n",
      "{'claim': 'Happiness in Slavery is a gospel song by Nine Inch Nails.', 'label': 'NOT ENOUGH INFO', 'evidence': [['American_Thighs', '3'], ['Almenara,_Minas_Gerais', '19'], ['American_Thighs', '0'], ['Almenara,_Minas_Gerais', '16'], ['Alan_Brown_-LRB-Australian_politician-RRB-', '10']]}\n",
      "\n",
      "\n",
      "{'claim': 'Andrew Kevin Walker is only Chinese.', 'label': 'REFUTES', 'evidence': [['Alta_Outcome_Document', '27'], ['Alta_Outcome_Document', '21'], ['Amuka', '0'], ['Alta_Outcome_Document', '12'], ['Alta_Outcome_Document', '23']]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_evidence(res_data):\n",
    "    for key in list(res_data)[:10]:\n",
    "        res_data[key][\"evidence\"] = []\n",
    "        tfidf_result = retrieval_evidence(res_data[key][\"claim\"],keys[:100],final_dic)\n",
    "        for res in tfidf_result:\n",
    "            res_data[key][\"evidence\"].append([document[res].split()[0], document[res].split()[1]])\n",
    "    return res_data\n",
    "\n",
    "#testing\n",
    "predicted_train = get_evidence(res_data)\n",
    "for key in list(predicted_train)[:10]:\n",
    "    print(predicted_train[key])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
