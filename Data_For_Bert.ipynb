{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe for Bert Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T08:03:47.689720Z",
     "start_time": "2019-05-23T08:03:47.613270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the devset data is: 5001\n",
      "Length of the bert data is: 5001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# with open('train.json', 'r') as f1: \n",
    "#         train_data = json.load(f1) \n",
    "# print(\"Length of the train data is: \" + str(len(train_data)))\n",
    "\n",
    "with open('devset.json', 'r') as f1: \n",
    "        dev_data = json.load(f1) \n",
    "print(\"Length of the devset data is: \" + str(len(dev_data)))\n",
    "\n",
    "with open('result_dev_523_3_tfidf.json', 'r') as f2:  # store result \n",
    "        bert_data = json.load(f2) \n",
    "print(\"Length of the bert data is: \" + str(len(bert_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T08:03:56.485548Z",
     "start_time": "2019-05-23T08:03:56.475299Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in dev_data.items():\n",
    "    bert_data[key]['ground_true'] = value['evidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T08:08:35.224282Z",
     "start_time": "2019-05-23T08:08:35.156550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Colin Kaepernick became a starting quarterback...</td>\n",
       "      <td>[Colin_Kaepernick, 6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colin Kaepernick became a starting quarterback...</td>\n",
       "      <td>[Colin_Kaepernick, 8]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colin Kaepernick became a starting quarterback...</td>\n",
       "      <td>[Colin_Kaepernick, 7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fox 2000 Pictures released the film Soul Food.</td>\n",
       "      <td>[Fox_-LRB-film-RRB-, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fox 2000 Pictures released the film Soul Food.</td>\n",
       "      <td>[Food_-LRB-film-RRB-, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fox 2000 Pictures released the film Soul Food.</td>\n",
       "      <td>[Food_-LRB-disambiguation-RRB-, 12]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anne Rice was born in New Jersey.</td>\n",
       "      <td>[Anne_Rice, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anne Rice was born in New Jersey.</td>\n",
       "      <td>[Anne_Rice, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anne Rice was born in New Jersey.</td>\n",
       "      <td>[New_-LRB-surname-RRB-, 28]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Telemundo is a English-language television net...</td>\n",
       "      <td>[Telemundo, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Colin Kaepernick became a starting quarterback...   \n",
       "1  Colin Kaepernick became a starting quarterback...   \n",
       "2  Colin Kaepernick became a starting quarterback...   \n",
       "3     Fox 2000 Pictures released the film Soul Food.   \n",
       "4     Fox 2000 Pictures released the film Soul Food.   \n",
       "5     Fox 2000 Pictures released the film Soul Food.   \n",
       "6                  Anne Rice was born in New Jersey.   \n",
       "7                  Anne Rice was born in New Jersey.   \n",
       "8                  Anne Rice was born in New Jersey.   \n",
       "9  Telemundo is a English-language television net...   \n",
       "\n",
       "                              evidence  prediction  \n",
       "0                [Colin_Kaepernick, 6]           0  \n",
       "1                [Colin_Kaepernick, 8]           0  \n",
       "2                [Colin_Kaepernick, 7]           0  \n",
       "3              [Fox_-LRB-film-RRB-, 1]           0  \n",
       "4             [Food_-LRB-film-RRB-, 0]           0  \n",
       "5  [Food_-LRB-disambiguation-RRB-, 12]           0  \n",
       "6                       [Anne_Rice, 5]           0  \n",
       "7                       [Anne_Rice, 0]           0  \n",
       "8          [New_-LRB-surname-RRB-, 28]           0  \n",
       "9                       [Telemundo, 0]           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "i = 0\n",
    " \n",
    "claim_list = []       # first 50000 claims in the training dataset \n",
    "evidence_list = []    #  evidence predicted by using tfidf method top3 \n",
    "prediction_list = []  # 1 or 0, 1 if this claim has this evidence, 0 otherwise\n",
    "\n",
    "for key in list(bert_data)[:100]:\n",
    "    claim= (bert_data[key][\"claim\"])\n",
    "    \n",
    "    evidences = bert_data[key][\"evidence\"]\n",
    "    if len(evidences) >= 1:\n",
    "        for evidence in evidences:\n",
    "            claim_list.append(claim)\n",
    "            evidence_list.append(evidence)\n",
    "            \n",
    "            if len(bert_data[key][\"ground_true\"]) >= 1:   \n",
    "                if evidence in bert_data[key][\"ground_true\"]:\n",
    "                    prediction_list.append(1)\n",
    "                else:\n",
    "                    prediction_list.append(0)\n",
    "            else:\n",
    "                prediction_list.append(0)\n",
    "    \n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "final_data = {\n",
    "    \"claim\": claim_list,\n",
    "    \"evidence\": evidence_list,\n",
    "    \"prediction\": prediction_list\n",
    "}\n",
    "corpus_df = pd.DataFrame(final_data)\n",
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_processed_corpus_df = pd.read_pickle(\"./processed_corpus.pkl\")\n",
    "load_processed_corpus_df = pd.read_csv(\"./new_wiki.csv\")\n",
    "print(load_processed_corpus_df.shape)\n",
    "load_processed_corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_text = []\n",
    "for evidence in evidence_list:\n",
    "    evidence[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.to_csv('bert_data.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
